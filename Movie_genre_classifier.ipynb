{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file using the file path uploaded\n",
        "data = pd.read_csv(\"output.csv\")\n",
        "\n",
        "# Preprocess the data to check redundancy\n",
        "data = data.dropna(subset=['Genre', 'Description'])\n",
        "label_encoder = LabelEncoder()\n",
        "data['Genre_encoded'] = label_encoder.fit_transform(data['Genre'])\n",
        "\n",
        "# Prepare the text descriptions and labels\n",
        "X = data['Description']\n",
        "y = data['Genre_encoded']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization for words classification\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Model Training\n",
        "logistic_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logistic_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Function to predict genre and its probability for a new description\n",
        "def predict_genre(description):\n",
        "    description_tfidf = tfidf_vectorizer.transform([description])\n",
        "    prediction = logistic_classifier.predict(description_tfidf)\n",
        "    probabilities = logistic_classifier.predict_proba(description_tfidf)\n",
        "    predicted_genre = label_encoder.inverse_transform(prediction)[0]\n",
        "    predicted_probability = probabilities[0][prediction][0]\n",
        "\n",
        "    return predicted_genre, predicted_probability\n",
        "\n",
        "# Example usage\n",
        "new_description = input(\"Enter the description: \")\n",
        "predicted_genre, predicted_probability = predict_genre(new_description)\n",
        "print(f\"\\nPredicted Genre: {predicted_genre}\")\n",
        "print(f\"Probability: {predicted_probability:.2f}\")"
      ],
      "metadata": {
        "id": "uFJLz69y2XpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb31bf0-c445-421c-8497-a5cefda9344e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the description: In \"Voices of the Deep,\" dive into the uncharted territories of the world's oceans to uncover the hidden lives of the extraordinary creatures that inhabit the depths. This documentary follows a team of marine biologists, oceanographers, and filmmakers as they embark on a groundbreaking expedition to explore underwater ecosystems that have never been captured on film before. From bioluminescent creatures in the midnight zone to the ancient, colossal squids lurking in the abyss, witness the marvels of marine life that defy imagination. The documentary also highlights the crucial role these ecosystems play in the planet's health and the urgent need for their conservation amidst the growing threats of climate change and human activity. Through stunning underwater cinematography and expert insights, \"Voices of the Deep\" offers a mesmerizing and educational journey into the heart of the ocean, revealing its mysteries and the efforts to protect its future.\n",
            "\n",
            "Predicted Genre: documentary\n",
            "Probability: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Input and output file paths\n",
        "input_file = 'train_data.txt'\n",
        "output_file = 'output.csv'\n",
        "\n",
        "# Function to parse each line of text and extract details\n",
        "def parse_line(line):\n",
        "    pattern = r'(\\d+) ::: (.+?) \\((\\d{4})\\) ::: (.+?) ::: (.+)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.groups()\n",
        "    return None\n",
        "\n",
        "# Read the text file and parse each line\n",
        "data = []\n",
        "with open(input_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parsed = parse_line(line.strip())\n",
        "        if parsed:\n",
        "            data.append(parsed)\n",
        "\n",
        "# Write parsed data to CSV\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    # Write header\n",
        "    csvwriter.writerow(['ID', 'Title', 'Year', 'Genre', 'Description'])\n",
        "    # Write data rows\n",
        "    csvwriter.writerows(data)\n",
        "\n",
        "print(f\"Data successfully written to {output_file}\")"
      ],
      "metadata": {
        "id": "H02MRJR3yhLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}